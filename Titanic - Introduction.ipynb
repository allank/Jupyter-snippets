{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "## Titanic Data\n",
    "\n",
    "This notebook works through Python machine learning using [scikit-learn](http://scikit-learn.org/).\n",
    "\n",
    "This code and much of the explanation is from [this blog post](http://blog.socialcops.com/engineering/machine-learning-python).\n",
    "\n",
    "The Titanic passenger manifest data is from [here](http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.xls)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation, tree, preprocessing\n",
    "import sklearn.ensemble as ske"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new libraries to import are from [scikit-learn](http://scikit-learn.org/stable/).\n",
    "\n",
    "From `sklearn` we'll be using the following modules:\n",
    "\n",
    "- `cross_validation` allows us to split our data into training and test sets, so that we can test our trained model against unseen data to avoid overfitting\n",
    "- `tree` allows us to create a decision tree to be used for classification\n",
    "- `preprocessing` contains a bunch of utility functions to convert your raw data into a representation of your data that is more suitable for working with inside the various machine learning algorithms\n",
    "\n",
    "We can use the `sklearn.ensemble` module to combine the results of several estimators to improve the results we would achive by using just one estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, import the Titanic data from the Excel document provided.  The Pandas `read_excel` function works just like `read_csv`, but because an Excel document can contain multiple sheets, we also need to specify which sheet to import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = pd.read_excel('titanic3.xls', 'titanic3', index_col=None, na_values=['NA'])\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in the DataFrame contain the following information:\n",
    "\n",
    "- **`pclass`** is the Passenger ticket class.  1 = First, 2 = Second and 3 = Third\n",
    "- **`survived`** is an indicator of whether the passenger survived or not.  1 means that they survived and 0 they did not.\n",
    "- **`name`** is the passenger name\n",
    "- **`sex`** the sex of the passenger, male or female\n",
    "- **`age`** age of the passnger\n",
    "- **`sibsp`** is the number of siblings or spouses aboard\n",
    "- **`parch`** is the number of parents or children aboard\n",
    "- **`ticket`** is the passengers ticket number\n",
    "- **`fare`** is the passenger cabin fare\n",
    "- **`cabin`** is the cabin number for the passenger\n",
    "- **`embarked`** is the port where this passenger embarked.  C = Cherbourg, Q = Queenstown and S = Shouthampton.\n",
    "- **`boat`** is the lifeboat number (for those passengers that survived)\n",
    "- **`body`** is the body number for the passenger, if they did not survive and the body was recovered\n",
    "- **`home.dest`** is the passengers home and destination\n",
    "\n",
    "> More detail about the Titanic 3 dataset can be [found here](http://campus.lakeforest.edu/frank/FILES/MLFfiles/Bio150/Titanic/TitanicMETA.pdf).\n",
    "\n",
    "As you can see there is a lot of missing data, but already we can work out things like the average survival rate on the Titanic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3819709702062643"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.survived.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by cleaning up the data we have.  A quick inspection of the DataFrame with the `count` method will give us a bit of an idea of which columns are complete, and which are not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass       1309\n",
       "survived     1309\n",
       "name         1309\n",
       "sex          1309\n",
       "age          1046\n",
       "sibsp        1309\n",
       "parch        1309\n",
       "ticket       1309\n",
       "fare         1308\n",
       "cabin         295\n",
       "embarked     1307\n",
       "boat          486\n",
       "body          121\n",
       "home.dest     745\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to drop columns that won't be relevant.  Whether we found the body or not, what cabin they were in, which boat they took and what their home/destination was are all missing a lot of data so while they may be relevant (for example, cabin distance from a lifeboat might be a factor), the missing data will throw off our calculations.  To drop them us the `drop` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass      1309\n",
       "survived    1309\n",
       "name        1309\n",
       "sex         1309\n",
       "age         1046\n",
       "sibsp       1309\n",
       "parch       1309\n",
       "ticket      1309\n",
       "fare        1308\n",
       "embarked    1307\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = titanic_df.drop(['body','cabin','boat', 'home.dest'], axis=1)\n",
    "titanic_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's drop any rows that have missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass      1043\n",
       "survived    1043\n",
       "name        1043\n",
       "sex         1043\n",
       "age         1043\n",
       "sibsp       1043\n",
       "parch       1043\n",
       "ticket      1043\n",
       "fare        1043\n",
       "embarked    1043\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = titanic_df.dropna()\n",
    "titanic_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we're down to 1043 records from the original 1309, but we have complete data for all the columns.  Now we can digging in to the data.  Let's see how different ticket classes impacted on passenger survival rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.634752</td>\n",
       "      <td>39.083038</td>\n",
       "      <td>0.478723</td>\n",
       "      <td>0.414894</td>\n",
       "      <td>92.316091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.440613</td>\n",
       "      <td>29.506705</td>\n",
       "      <td>0.417625</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>21.855044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.262000</td>\n",
       "      <td>24.745000</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>0.442000</td>\n",
       "      <td>12.879299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        survived        age     sibsp     parch       fare\n",
       "pclass                                                    \n",
       "1       0.634752  39.083038  0.478723  0.414894  92.316091\n",
       "2       0.440613  29.506705  0.417625  0.390805  21.855044\n",
       "3       0.262000  24.745000  0.564000  0.442000  12.879299"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.groupby('pclass').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly being in First class gave you a better chance of survival.  We can go futher and look at how different genders fared in each of the passenger classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>female</th>\n",
       "      <td>0.961832</td>\n",
       "      <td>36.839695</td>\n",
       "      <td>0.564885</td>\n",
       "      <td>0.511450</td>\n",
       "      <td>112.485402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.350993</td>\n",
       "      <td>41.029250</td>\n",
       "      <td>0.403974</td>\n",
       "      <td>0.331126</td>\n",
       "      <td>74.818213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>female</th>\n",
       "      <td>0.893204</td>\n",
       "      <td>27.499191</td>\n",
       "      <td>0.514563</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>23.267395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.145570</td>\n",
       "      <td>30.815401</td>\n",
       "      <td>0.354430</td>\n",
       "      <td>0.208861</td>\n",
       "      <td>20.934335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>female</th>\n",
       "      <td>0.473684</td>\n",
       "      <td>22.185307</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.796053</td>\n",
       "      <td>14.655758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.169540</td>\n",
       "      <td>25.863027</td>\n",
       "      <td>0.488506</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>12.103374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               survived        age     sibsp     parch        fare\n",
       "pclass sex                                                        \n",
       "1      female  0.961832  36.839695  0.564885  0.511450  112.485402\n",
       "       male    0.350993  41.029250  0.403974  0.331126   74.818213\n",
       "2      female  0.893204  27.499191  0.514563  0.669903   23.267395\n",
       "       male    0.145570  30.815401  0.354430  0.208861   20.934335\n",
       "3      female  0.473684  22.185307  0.736842  0.796053   14.655758\n",
       "       male    0.169540  25.863027  0.488506  0.287356   12.103374"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_sex_grouping = titanic_df.groupby(['pclass','sex']).mean()\n",
    "class_sex_grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, women were much more likely to survive than men - \"women and children first\".\n",
    "\n",
    "To have a look at the survival rate by age, we're going to do two things:  First we're going to organise the ages of the passengers into bins, and then graph the average survival rate of the passengers in each of the bins. \n",
    "\n",
    "First, let's create our bins - we'll want to lump passengers together within 10 year windows, so 0 to 10, 10 to 20, 20 to 30 etc.  To do this we need to create an array of those values - we could type them out, but Numpy has a function to do that; `arange`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 10, 20, 30, 40, 50, 60, 70, 80])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 90, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from 0, stopping before 90, in steps of 10 - gives us the array we need.  Now we can feed that into the Pandas `cut` function.  The `cut` function will look at each of the elements we pass it and decide which of the bins it fits in to.  So we want to bin the `age` column, and sort the ages into the bin of 10 year windows from 0 through to 80:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_by_age = pd.cut(titanic_df[\"age\"], np.arange(0, 90, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a quick look at the age values in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29.0000\n",
       "1     0.9167\n",
       "2     2.0000\n",
       "3    30.0000\n",
       "4    25.0000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df['age'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and also what the `cut` function has done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (20, 30]\n",
       "1     (0, 10]\n",
       "2     (0, 10]\n",
       "3    (20, 30]\n",
       "4    (20, 30]\n",
       "Name: age, dtype: category\n",
       "Categories (8, object): [(0, 10] < (10, 20] < (20, 30] < (30, 40] < (40, 50] < (50, 60] < (60, 70] < (70, 80]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_by_age.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the age of the first passenger is 29, so `cut` has put that in the bin that ranges from 20 to 30.  The third passenger was 2 years old, and is in the bin that ranges from 0 to 10.\n",
    "\n",
    "Now the last thing to do is to get the averages of our columns by grouping on our new binned data and returning the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0, 10]</th>\n",
       "      <td>2.651163</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>4.304264</td>\n",
       "      <td>1.709302</td>\n",
       "      <td>1.406977</td>\n",
       "      <td>29.436044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(10, 20]</th>\n",
       "      <td>2.524691</td>\n",
       "      <td>0.395062</td>\n",
       "      <td>17.283951</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.395062</td>\n",
       "      <td>28.807050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(20, 30]</th>\n",
       "      <td>2.371191</td>\n",
       "      <td>0.371191</td>\n",
       "      <td>25.324100</td>\n",
       "      <td>0.326870</td>\n",
       "      <td>0.218837</td>\n",
       "      <td>28.159013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(30, 40]</th>\n",
       "      <td>2.114833</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>35.107656</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.416268</td>\n",
       "      <td>42.523045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(40, 50]</th>\n",
       "      <td>1.787879</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>45.367424</td>\n",
       "      <td>0.378788</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>47.254231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pclass  survived        age     sibsp     parch       fare\n",
       "age                                                                   \n",
       "(0, 10]   2.651163  0.581395   4.304264  1.709302  1.406977  29.436044\n",
       "(10, 20]  2.524691  0.395062  17.283951  0.611111  0.395062  28.807050\n",
       "(20, 30]  2.371191  0.371191  25.324100  0.326870  0.218837  28.159013\n",
       "(30, 40]  2.114833  0.421053  35.107656  0.363636  0.416268  42.523045\n",
       "(40, 50]  1.787879  0.393939  45.367424  0.378788  0.409091  47.254231"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_grouping = titanic_df.groupby(group_by_age).mean()\n",
    "age_grouping.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's plot the survival rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10b19b310>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEtCAYAAAD+y1AoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119904610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "age_grouping['survived'].plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now that we've got a feel for the data and cleaned it up, let's move on to the machine learning part and see if we can use the data to make some predictions.  Let's just have a quick look at the data that we have again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare embarked  \n",
       "0  29.0000      0      0   24160  211.3375        S  \n",
       "1   0.9167      1      2  113781  151.5500        S  \n",
       "2   2.0000      1      2  113781  151.5500        S  \n",
       "3  30.0000      1      2  113781  151.5500        S  \n",
       "4  25.0000      1      2  113781  151.5500        S  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computer work better with numerical data than with text, so before we can begin training and testing, we need to clean up the text data and transform it into numerical values.  We could just select some arbitrary values (female = 1, male = 0) but this won't be terribly useful if we have a lot of data to work with.  This is where the `preprocessing` module come in.  It looks at the values you have in a column, generates labels for your data and updates it to use the new numerical values.  Before we jump in with the Titanic data, let's look at a toy example.  We need the `preprocessing` module from `sklearn`, but we already imported it, so I'm just repeating it (commented out) as a reminder.  Then, let's create some toy data - we'll work with a list of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "toy_data = ['Apple', 'Orange', 'Apple', 'Banana', 'Banana', 'Apple', 'Orange']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create a new `LabelEncoder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toy_le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of the process is to \"fit\" the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_le.fit(toy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see what `fit` has done by inspecting the internal property of the LabelEncoder object called `classes_`.  As you can see, it's worked out the unique values from our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple', 'Banana', 'Orange']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(toy_le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a list where index 0 is Apple, index 1 is Banana and index 2 is Orange. \n",
    "\n",
    "Now let's transform our `toy_data` and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1, 1, 0, 2])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_le.transform(toy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look back to the original data, the first element was `Apple` which has now been transformed to `0`, which corresponds to index 0 of the list we generated with the `fit` function.  Similarly, the second element was `Orange` that has been transformed to `2` that corresponds to index 2 in our list from the `fit` function.\n",
    "\n",
    "Now let's apply those same steps to our titanic data.  First, create the LabelEncoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, make a copy of the original data and apply the `fit` and `transform` methods of the LabelEncoder to `sex` and `embarked` columns of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processed_df = titanic_df.copy()\n",
    "processed_df.sex = le.fit_transform(processed_df.sex)\n",
    "processed_df.embarked = le.fit_transform(processed_df.embarked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning we want to work with categorical data, which `sex` and `embark` are.  Name and ticket number are not categorical (each one is unique) so they won't be valuable in our machine learning algorithm and we can drop them. Let's do that and have a look what we're got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived  sex      age  sibsp  parch      fare  embarked\n",
       "0       1         1    0  29.0000      0      0  211.3375         2\n",
       "1       1         1    1   0.9167      1      2  151.5500         2\n",
       "2       1         0    0   2.0000      1      2  151.5500         2\n",
       "3       1         0    1  30.0000      1      2  151.5500         2\n",
       "4       1         0    0  25.0000      1      2  151.5500         2"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = processed_df.drop(['name','ticket'],axis=1)\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to separate our data into two parts, typicall called `X` and `y`.  `X` will be all of our data _except_ the column we want to train to predict, and `y` the values we have.  So in this case we will take the `survived` column and store that in `y` and then store the rest of the columns in `X`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = processed_df.drop(['survived'], axis=1).values\n",
    "y = processed_df['survived'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we train the algorithm it will look for patterns in each of the rows in `X` that result in the corresponding value in `y`.  To do the actual training we need to split the data into training and testing data.  This let's us use the training data to come up with the model and then test that model on the test data - because we are testing on data that wasn't used in training, we wont be overfitting.  The `cross_validation` module of `sklearn` has a function `train_test_split` that returns test and train sets for our `X` and `y` data.  You pass in the `X` and `y` data sets along with a ratio of how much data you want to use as the test - in this case we're going to train with 80% of the data and test with the remaining 20%:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can begin training using the training data sets (`X_train` and `y_train`) and testing the result with the test data (`X_test` and `y_test`).  scikit-learn has a number of different classifiers, let's start with a Decision Tree Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_dt = tree.DecisionTreeClassifier(max_depth=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can train (using the `fit` function) the data to the classifier using the training data, and test it's accuracy using the `score` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8133971291866029"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dt.fit(X_train, y_train)\n",
    "clf_dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test a couple of others as well - a Random Forest Classifier and a Gradient Boosting Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80382775119617222"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf = ske.RandomForestClassifier(n_estimators=50)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "clf_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84688995215311003"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gb = ske.GradientBoostingClassifier(n_estimators=50)\n",
    "clf_gb.fit(X_train, y_train)\n",
    "clf_gb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass all three of our classifiers in to a Voting Classifier that will return the best results from all of the classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84688995215311003"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf = ske.VotingClassifier([('dt', clf_dt), ('rf', clf_rf), ('gb', clf_gb)])\n",
    "eclf.fit(X_train, y_train)\n",
    "eclf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's create a completely new passenger and predict whether they would have survived or not.  Remember that our `X` data was a grid of rows and columns, so we need to create a list of lists with our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_passenger = [[2, 0, 40, 0, 0, 200, 1]]\n",
    "eclf.predict(new_passenger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model reckons that a 40 year old female passenger with a second class ticket would have survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
